{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6cddb5-f5ba-4b74-a794-7209de0aa2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger('BeamSearchRanker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "stream_handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "# Prevent logs from propagating to the root logger\n",
    "logger.propagate = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74462c2-f225-4690-b614-8d41e5d5e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # model configuration\n",
    "    # base_model: str = \"ollama_chat/qwen2.5:1.5b-instruct-q8_0\"\n",
    "    base_model: str = \"ollama_chat/gemma2:2b-instruct-q8_0\"\n",
    "    # base_model: str = \"ollama_chat/llama3.2:1b-instruct-q8_0\"\n",
    "    # base_model: str = \"ollama_chat/exaone3.5:2.4b-instruct-q8_0\"\n",
    "    # base_model: str = \"ollama_chat/granite3.1-dense:2b-instruct-q8_0\"\n",
    "    # base_model: str = \"ollama_chat/granite3.1-moe:3b-instruct-q8_0\"\n",
    "    # base_model:str = \"ollama_chat/llama3.2:3b-instruct-q8_0\"\n",
    "    temperature: float = 1.0\n",
    "    # teacher_model: str = \"openrouter/deepseek/deepseek-chat\"\n",
    "    # teacher_model: str = \"openrouter/meta-llama/Llama-3.3-70B-Instruct-Turbo\"\n",
    "    teacher_model: str = \"openrouter/qwen/qwen-2.5-72b-instruct\"\n",
    "    # teacher_model: str = \"openrouter/qwen/qwq-32b-preview\"\n",
    "    teacher_temperature: float = 0.8\n",
    "\n",
    "    reward_model: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "\n",
    "    # dataset\n",
    "    dataset: str = \"HuggingFaceH4/MATH-500\"\n",
    "\n",
    "    # APIKEY (if using api for teacher)\n",
    "    api_key: str | None = None\n",
    "\n",
    "\n",
    "config = Config(\n",
    "    api_key = os.environ[\"OPENROUTER_APIKEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0592bcbd-d134-49f8-bcf9-25f93c073dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "# using cross encoder as reward model\n",
    "reward_model = CrossEncoder(config.reward_model)\n",
    "\n",
    "# small, locally hosted base model\n",
    "lm = dspy.LM(config.base_model, api_base='http://localhost:11434', api_key='', temperature=config.temperature,  cache=False)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# teacher model for instruction proposal\n",
    "teacher_lm = dspy.LM(config.teacher_model, api_key=config.api_key, temperature=config.temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db1f5df-12b6-4f89-bc9d-42697757d197",
   "metadata": {},
   "source": [
    "# Populate BM25S index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc2aa1b-365f-49ba-a942-154ef638a2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/25657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/25657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/25657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/25657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bm25s\n",
    "import Stemmer\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"BeIR/scidocs\", \"corpus\")\n",
    "corpus = dataset[\"corpus\"][\"text\"]\n",
    "\n",
    "# optional: create a stemmer\n",
    "stemmer = Stemmer.Stemmer(\"english\")\n",
    "\n",
    "# Tokenize the corpus and only keep the ids (faster and saves memory)\n",
    "corpus_tokens = bm25s.tokenize(corpus, stopwords=\"en\", stemmer=stemmer)\n",
    "\n",
    "# Create the BM25 model and index the corpus\n",
    "retriever = bm25s.BM25()\n",
    "retriever.index(corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1dfe78-444f-45d0-8fe1-d25553ac2791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"1 Introduction Jackson (Jackson 95) recognises the vital difference between an application's domain and its code: two different worlds, each with its own language, experts, ways of thinking etc. A finished application forms the intersection between these worlds. The difficult job of the software engineer is to build a bridge between these worlds, at the same time as solving problems in both worlds.\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def _query_bm25(corpus, query, k=5):\n",
    "    query_tokens = bm25s.tokenize(query, stemmer=stemmer)\n",
    "    results, scores = retriever.retrieve(query_tokens, k=k)\n",
    "    return list(map(lambda i: corpus[i], results[0]))\n",
    "\n",
    "query_bm25 = partial(_query_bm25, corpus)\n",
    "\n",
    "query_bm25(\"hello world\", k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9421c8-6c57-4375-bcf8-f14eb496ebc4",
   "metadata": {},
   "source": [
    "# DSPy Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e656a8-713a-4780-9280-63123562003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_TERMS = \"\"\"\n",
    "Help improve the search results from the BM25 index.\n",
    "Analyze the previous search terms and results, and creatively write updated search terms to help find better results.\n",
    "Reference the previous results to understand the kind of data in the index.\n",
    "Create process steps that help resolve the data in the dataset and determine the next set of terms.\n",
    "\n",
    "Focus on expanding the query terms so that the results do not overlap the previous results.\n",
    "Generate new *unique* search terms to explore the index for different results that may apply to the query.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55954b15-0045-4876-87e7-6405667e9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class GenerateNewSearchTerms(dspy.Signature):\n",
    "    __doc__ = GENERATE_TERMS\n",
    "    \n",
    "    query: str = dspy.InputField(desc=\"The original search query\")\n",
    "    previous_search_terms: list[str] = dspy.InputField(desc=\"Previous list of search terms.\")\n",
    "    previous_results: list[str] = dspy.InputField(desc=\"The previous top search results.\")\n",
    "    #steps: list[str] = dspy.OutputField(desc=\"List of process steps to determine how to identify new terms\")\n",
    "    strategy: str = dspy.OutputField(desc=\"In one sentence, concisely mention how will you improve the search terms?\")\n",
    "    new_search_terms: list[str] = dspy.OutputField(desc=\"New search terms (tokens) to improve results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8cf2a43-54a5-4b3e-81ff-5050b4b01a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import heapq\n",
    "from typing import List, Tuple, Dict\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import dspy  # Ensure dspy is correctly imported based on your framework\n",
    "\n",
    "\n",
    "def hash_result(result: str) -> str:\n",
    "    \"\"\"Generate a SHA-256 hash for a given result string.\"\"\"\n",
    "    return hashlib.sha256(result.encode('utf-8')).hexdigest()\n",
    "\n",
    "\n",
    "class Scorer:\n",
    "    \"\"\"\n",
    "    Handles scoring of results, caching scores, and maintaining a top-k heap.\n",
    "    \"\"\"\n",
    "    def __init__(self, k: int):\n",
    "        self.k = k\n",
    "        self.score_cache: Dict[str, float] = defaultdict(float)\n",
    "        self.heap: List[Tuple[float, str]] = []\n",
    "        self.logger = logging.getLogger('Scorer')\n",
    "\n",
    "    @classmethod\n",
    "    def new(cls, k: int = 5):\n",
    "        \"\"\"Factory method to create a new Scorer instance.\"\"\"\n",
    "        return cls(k)\n",
    "\n",
    "    def score_results(self, query: str, results: List[str], reward_model) -> List[float]:\n",
    "        \"\"\"\n",
    "        Scores the given results using the reward model.\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query.\n",
    "            results (List[str]): List of result strings to score.\n",
    "            reward_model: The model used to score the results.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: Scores corresponding to the results.\n",
    "        \"\"\"\n",
    "        results_to_score = [\n",
    "            result for result in results\n",
    "            if hash_result(result) not in self.score_cache\n",
    "        ]\n",
    "\n",
    "        # Initialize scores list with cached scores or None\n",
    "        scores = []\n",
    "        for result in results:\n",
    "            result_hash = hash_result(result)\n",
    "            if result_hash in self.score_cache:\n",
    "                score = self.score_cache[result_hash]\n",
    "                self.logger.debug(f\"Cached Score: {score:.3f}, Hash: {result_hash}\")\n",
    "                self._push_to_heap(score, result, result_hash)\n",
    "                scores.append(score)\n",
    "            else:\n",
    "                scores.append(None)  # Placeholder for new scores\n",
    "\n",
    "        # Batch score the new results\n",
    "        if results_to_score:\n",
    "            try:\n",
    "                query_result_pairs = [(query, result) for result in results_to_score]\n",
    "                logger.debug(f\"Scoring {len(results_to_score)} pairs...\")\n",
    "                new_scores = reward_model.predict(query_result_pairs)\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error during batch scoring: {e}\")\n",
    "                new_scores = [0.0] * len(results_to_score)\n",
    "\n",
    "            for result, score in zip(results_to_score, new_scores):\n",
    "                result_hash = hash_result(result)\n",
    "                self.score_cache[result_hash] = score\n",
    "                self.logger.debug(f\"New Score: {score:.3f}, Hash: {result_hash}\")\n",
    "                self._push_to_heap(score, result, result_hash)\n",
    "\n",
    "            # Update the scores list with new scores\n",
    "            score_iter = iter(new_scores)\n",
    "            scores = [s if s is not None else next(score_iter) for s in scores]\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def _push_to_heap(self, score: float, result: str, result_hash: str):\n",
    "        \"\"\"\n",
    "        Push a result with its score to the heap, maintaining the top-k results.\n",
    "\n",
    "        Args:\n",
    "            score (float): The score of the result.\n",
    "            result (str): The result string.\n",
    "            result_hash (str): The hash of the result.\n",
    "        \"\"\"\n",
    "        if len(self.heap) < self.k:\n",
    "            heapq.heappush(self.heap, (score, result))\n",
    "            self.logger.debug(f\"Pushed to heap: Score: {score:.3f}, Hash: {result_hash}\")\n",
    "        else:\n",
    "            if score > self.heap[0][0]:\n",
    "                popped = heapq.heappushpop(self.heap, (score, result))\n",
    "                popped_hash = hash_result(popped[1])\n",
    "                self.logger.debug(\n",
    "                    f\"Popped from heap: Score: {popped[0]:.3f}, Hash: {popped_hash}\"\n",
    "                )\n",
    "                self.logger.debug(\n",
    "                    f\"Pushed to heap: Score: {score:.3f}, Hash: {result_hash}\"\n",
    "                )\n",
    "\n",
    "    def calculate_average_score(self, results: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the average score of the given results.\n",
    "\n",
    "        Args:\n",
    "            results (List[str]): List of result strings.\n",
    "\n",
    "        Returns:\n",
    "            float: The average score.\n",
    "        \"\"\"\n",
    "        cached_scores = [\n",
    "            self.score_cache[hash_result(r)] for r in results\n",
    "            if hash_result(r) in self.score_cache\n",
    "        ]\n",
    "        average_score = (\n",
    "            sum(cached_scores) / len(cached_scores)\n",
    "            if cached_scores else 0.0\n",
    "        )\n",
    "        self.logger.info(f\"Calculated Average Score: {average_score:.3f}\")\n",
    "        return average_score\n",
    "\n",
    "    def get_topk(self) -> Tuple[List[str], float]:\n",
    "        \"\"\"\n",
    "        Retrieve the top-k results from the heap.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[str], float]: Top-k results and their average score.\n",
    "        \"\"\"\n",
    "        sorted_heap = sorted(self.heap, key=lambda x: x[0], reverse=True)\n",
    "        top_results = [result for _, result in sorted_heap]\n",
    "        average_top_score = (\n",
    "            sum(score for score, _ in sorted_heap) / len(sorted_heap)\n",
    "            if sorted_heap else 0.0\n",
    "        )\n",
    "        self.logger.info(f\"Top-{self.k} Average Score: {average_top_score:.3f}\")\n",
    "        return top_results, average_top_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81446c6e-0174-4593-8149-618805812dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchRanker(dspy.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        reward_model,\n",
    "        depth: int = 3,\n",
    "        expansions: int = 3,\n",
    "        k: int = 5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the BeamSearchRanker.\n",
    "\n",
    "        Args:\n",
    "            reward_model: The model used to score the results.\n",
    "            depth (int): Number of expansion steps.\n",
    "            expansions (int): Number of expansions per depth step.\n",
    "            k (int): Number of top results to keep.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.expansions = expansions\n",
    "        self.k = k\n",
    "        self.reward_model = reward_model\n",
    "\n",
    "        # Initialize predictors and summarizer\n",
    "        self.predictors = [\n",
    "            dspy.ChainOfThought(GenerateNewSearchTerms) \n",
    "            for _ in range(depth)\n",
    "        ]\n",
    "        self.summarizer = dspy.ChainOfThought(\"query, context: list[str] -> answer\")\n",
    "\n",
    "        # Initialize logger\n",
    "        self.logger = logging.getLogger('BeamSearchRanker')\n",
    "\n",
    "    def forward(self, query: str) -> dspy.Prediction:\n",
    "        \"\"\"\n",
    "        Perform the beam search ranking.\n",
    "\n",
    "        Args:\n",
    "            query (str): The initial search query.\n",
    "\n",
    "        Returns:\n",
    "            dspy.Prediction: The prediction containing terms, results, score, and summary.\n",
    "        \"\"\"\n",
    "        self._initialize_search(query)\n",
    "\n",
    "        # Instantiate a new Scorer for this forward pass\n",
    "        scorer = Scorer.new(k=self.k)\n",
    "\n",
    "        for depth_step in range(self.depth):\n",
    "            self.logger.info(f\"\\n--- Depth Step {depth_step + 1}/{self.depth} ---\")\n",
    "            best_terms, best_results, top_score = self._process_depth_step(\n",
    "                query, depth_step, self.expansions, self.predictors[depth_step], scorer\n",
    "            )\n",
    "\n",
    "            if best_terms:\n",
    "                self.terms.update(\" \".join(best_terms).split())\n",
    "                self.results.update(best_results)\n",
    "                self.logger.info(f\"Total unique results so far: {len(self.results)}\")\n",
    "            else:\n",
    "                self.logger.info(\"No better expansion found. Stopping early.\")\n",
    "                break\n",
    "\n",
    "        final_results, final_score = scorer.get_topk()\n",
    "        self.logger.info(f\"Final Score: {final_score:.3f}\")\n",
    "\n",
    "        summary = self.summarizer(query=query, context=final_results)\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            terms=list(self.terms),\n",
    "            results=final_results,\n",
    "            score=final_score,\n",
    "            summary=summary\n",
    "        )\n",
    "\n",
    "    def _initialize_search(self, query: str):\n",
    "        \"\"\"\n",
    "        Initialize the search by performing the initial search.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"\\n--- Starting Forward Pass ---\")\n",
    "\n",
    "        # Initial search\n",
    "        initial_results = query_bm25(query, k=self.k)\n",
    "        self.terms = set(query.split())\n",
    "        self.results = set(initial_results)\n",
    "        self.logger.info(f\"Initial Results: {len(initial_results)}\")\n",
    "\n",
    "    def _process_depth_step(\n",
    "        self, \n",
    "        query: str, \n",
    "        depth_step: int, \n",
    "        expansions: int, \n",
    "        predictor, \n",
    "        scorer: Scorer\n",
    "    ) -> Tuple[set, set, float]:\n",
    "        \"\"\"\n",
    "        Process a single depth step with the given predictor and number of expansions.\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query.\n",
    "            depth_step (int): Current depth step.\n",
    "            expansions (int): Number of expansions.\n",
    "            predictor: The predictor to generate new search terms.\n",
    "            scorer (Scorer): The scorer instance to handle scoring.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[set, set, float]: Best search terms, best results, and top average score.\n",
    "        \"\"\"\n",
    "        top_score = -float('inf')\n",
    "        best_terms = set()\n",
    "        best_results = set()\n",
    "\n",
    "        for expansion in range(expansions):\n",
    "            self.logger.info(\n",
    "                f\"--- Expansion {expansion + 1}/{expansions} ---\"\n",
    "            )\n",
    "            new_search_terms, expanded_results = self._perform_expansion(query, predictor)\n",
    "            self.logger.info(\n",
    "                f\"Expansion {expansion + 1}/{expansions} - Generated {len(expanded_results)} results\"\n",
    "            )\n",
    "\n",
    "            # Handle results using Scorer\n",
    "            scorer.score_results(query, expanded_results, self.reward_model)\n",
    "\n",
    "            # Calculate average score for the current expansion\n",
    "            average_expansion_score = scorer.calculate_average_score(expanded_results)\n",
    "            self.logger.info(\n",
    "                f\"Expansion {expansion + 1} - Avg Score: {average_expansion_score:.3f}\"\n",
    "            )\n",
    "\n",
    "            # Update best terms and results based on average score\n",
    "            if average_expansion_score > top_score:\n",
    "                self.logger.info(\n",
    "                    f\"Updating best terms and results (Expansion {expansion + 1})...\"\n",
    "                )\n",
    "                top_score = average_expansion_score\n",
    "                best_terms = set(new_search_terms)\n",
    "                best_results = set(expanded_results)\n",
    "\n",
    "        return best_terms, best_results, top_score\n",
    "\n",
    "    def _perform_expansion(self, query: str, predictor):\n",
    "        \"\"\"\n",
    "        Use the predictor to generate new search terms and perform an expanded search.\n",
    "\n",
    "        Args:\n",
    "            query (str): The current query.\n",
    "            predictor: The predictor to generate new search terms.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[str], List[str]]: New search terms and expanded results.\n",
    "        \"\"\"\n",
    "        prediction = predictor(\n",
    "            query=query,\n",
    "            previous_search_terms=list(self.terms),\n",
    "            previous_results=list(self.results)\n",
    "        )\n",
    "        self.logger.info(prediction.strategy)\n",
    "        new_search_terms = prediction.new_search_terms\n",
    "        new_query = \" \".join(new_search_terms)\n",
    "        expanded_results = query_bm25(new_query, k=self.k)\n",
    "        return new_search_terms, expanded_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798ec661-90e9-4695-8794-d980e335be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BeamSearchRanker(reward_model=reward_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c53280-9330-4d1f-b694-ef64bafef7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:16,904 - INFO - \n",
      "--- Starting Forward Pass ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:17,007 - INFO - Initial Results: 5\n",
      "2024-12-23 21:04:17,007 - INFO - \n",
      "--- Depth Step 1/3 ---\n",
      "2024-12-23 21:04:17,007 - INFO - --- Expansion 1/3 ---\n",
      "2024-12-23 21:04:19,398 - INFO - To improve search terms, I'll broaden the focus by exploring various effects and impacts of being overweight/obese on specific aspects of health, including physical health issues, emotional wellbeing, social dynamics, and psychological factors.  I'll avoid simply repeating previous terms but delve into different facets of the issue.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:19,411 - INFO - Expansion 1/3 - Generated 5 results\n",
      "2024-12-23 21:04:19,412 - DEBUG - Scoring 5 pairs...\n",
      "2024-12-23 21:04:19,568 - INFO - Expansion 1 - Avg Score: -6.433\n",
      "2024-12-23 21:04:19,569 - INFO - Updating best terms and results (Expansion 1)...\n",
      "2024-12-23 21:04:19,569 - INFO - --- Expansion 2/3 ---\n",
      "2024-12-23 21:04:21,646 - INFO - We need to expand the search terms by focusing on health outcomes related to excess weight and obesity. This can involve incorporating synonyms, specific medical conditions associated with being overweight, and treatments or interventions for these conditions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:21,654 - INFO - Expansion 2/3 - Generated 5 results\n",
      "2024-12-23 21:04:21,654 - DEBUG - Scoring 2 pairs...\n",
      "2024-12-23 21:04:21,661 - INFO - Expansion 2 - Avg Score: -6.759\n",
      "2024-12-23 21:04:21,662 - INFO - --- Expansion 3/3 ---\n",
      "2024-12-23 21:04:23,806 - INFO - The query needs to encompass a wider range of implications for physical health, social life, and emotional well-being caused by being overweight. Focusing on diverse topics, like psychological impacts, long-term health risks, or specific lifestyle changes to manage weight, will expand the search space.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:23,815 - INFO - Expansion 3/3 - Generated 5 results\n",
      "2024-12-23 21:04:23,815 - DEBUG - Scoring 3 pairs...\n",
      "2024-12-23 21:04:23,822 - INFO - Expansion 3 - Avg Score: -6.291\n",
      "2024-12-23 21:04:23,822 - INFO - Updating best terms and results (Expansion 3)...\n",
      "2024-12-23 21:04:23,822 - INFO - Total unique results so far: 10\n",
      "2024-12-23 21:04:23,822 - INFO - \n",
      "--- Depth Step 2/3 ---\n",
      "2024-12-23 21:04:23,823 - INFO - --- Expansion 1/3 ---\n",
      "2024-12-23 21:04:27,137 - INFO - 1. **Identify Keywords and Phrases:** Extract relevant keywords and phrases from each document using natural language processing techniques or manually review them for potential topics. \n",
      "2. **Filter for Specific Terms:** Create focused queries using specific medical terms, scientific names, research areas (like energy conservation), or methods used in the documents. \n",
      "3. **Combine Keywords & Constraints:** Combine keywords with constraints like year of publication, journals where they appeared, etc. to refine search results.\n",
      "\n",
      "4.  **Refine and Iterate**: Analyze the initial search results, identifying relevant publications and applying them for further refinement.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:27,146 - INFO - Expansion 1/3 - Generated 5 results\n",
      "2024-12-23 21:04:27,146 - DEBUG - Scoring 5 pairs...\n",
      "2024-12-23 21:04:27,153 - INFO - Expansion 1 - Avg Score: -10.184\n",
      "2024-12-23 21:04:27,153 - INFO - Updating best terms and results (Expansion 1)...\n",
      "2024-12-23 21:04:27,153 - INFO - --- Expansion 2/3 ---\n",
      "2024-12-23 21:04:30,508 - INFO - 1. **Topic Extraction:**  First, identify the central themes within each document (Obesity research:  fat distribution, insulin sensitivity; Home energy system: load disaggregation). \n",
      "2. **Keyword Clustering:** Group related themes into larger clusters (e.g., \"Human physiology\", \"energy efficiency\").\n",
      "3. **Search Term Generation:** Construct concise search terms that capture the key concepts of each cluster, using a combination of broad and specific terms (e.g.,  \"body fat distribution,\" \"adipose tissue lipoprotein lipase\",  \"intelligent energy conservation\").\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:30,518 - INFO - Expansion 2/3 - Generated 5 results\n",
      "2024-12-23 21:04:30,518 - DEBUG - Scoring 1 pairs...\n",
      "2024-12-23 21:04:30,522 - INFO - Expansion 2 - Avg Score: -8.824\n",
      "2024-12-23 21:04:30,522 - INFO - Updating best terms and results (Expansion 2)...\n",
      "2024-12-23 21:04:30,522 - INFO - --- Expansion 3/3 ---\n",
      "2024-12-23 21:04:36,163 - INFO - Based on the abstract snippets, I can utilize information retrieval techniques like: \n",
      "* **keyword extraction:** Identify key terms and phrases across all abstracts for a broad understanding of the research domains.\n",
      "* **topic modeling:** Cluster similar abstracts to uncover underlying themes and subtopics for targeted search queries.\n",
      " * **semantic analysis:**  Deepen comprehension by analyzing relationships between words, concepts, and entities. This can help identify specific connections or relations that could inform new searches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:36,171 - INFO - Expansion 3/3 - Generated 5 results\n",
      "2024-12-23 21:04:36,172 - DEBUG - Scoring 1 pairs...\n",
      "2024-12-23 21:04:36,175 - INFO - Expansion 3 - Avg Score: -10.219\n",
      "2024-12-23 21:04:36,175 - INFO - Total unique results so far: 12\n",
      "2024-12-23 21:04:36,175 - INFO - \n",
      "--- Depth Step 3/3 ---\n",
      "2024-12-23 21:04:36,175 - INFO - --- Expansion 1/3 ---\n",
      "2024-12-23 21:04:42,815 - INFO - A multi-faceted approach is recommended: \n",
      "* **Target Keywords:**  Based on the provided text snippets, key phrases like 'body fat distribution', 'NILM research', 'load disaggregation', and related terms should be incorporated into a search query.\n",
      "* **Combine Approaches:** Investigate relevant datasets from publicly available resources such as PubMed Central, Kaggle, or government-sponsored health initiatives. Analyze existing studies on the topics of interest to refine the research direction.  \n",
      "* **Multidisciplinary Context:** Connect research with related fields like nutrition science, exercise physiology, and energy management to gain a broader perspective.\n",
      "* **Novel Applications:** Explore how NILM techniques can be applied in specific healthcare scenarios (e.g., personalized dietary recommendations, sleep improvement, or chronic condition management).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:42,824 - INFO - Expansion 1/3 - Generated 5 results\n",
      "2024-12-23 21:04:42,824 - INFO - Expansion 1 - Avg Score: -9.586\n",
      "2024-12-23 21:04:42,824 - INFO - Updating best terms and results (Expansion 1)...\n",
      "2024-12-23 21:04:42,824 - INFO - --- Expansion 2/3 ---\n",
      "2024-12-23 21:04:48,134 - INFO - A multi-faceted strategy can be used: \n",
      "\n",
      "1. **Database Exploration:** Start with online databases of NILM research, like arXiv, IEEE Xplore, and academic journals. Utilize keywords like 'load disaggregation,' 'non-intrusive load monitoring', and related terms like 'energy conservation,' 'smart home,' 'home energy management,' 'power consumption.' \n",
      "2. **Literature Review:**  Identify seminal papers in this field that discuss existing challenges, algorithm types, datasets used for evaluation. This will offer insights into current research trends and potential gaps.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:48,142 - INFO - Expansion 2/3 - Generated 5 results\n",
      "2024-12-23 21:04:48,143 - DEBUG - Scoring 4 pairs...\n",
      "2024-12-23 21:04:48,148 - INFO - Expansion 2 - Avg Score: -11.033\n",
      "2024-12-23 21:04:48,149 - INFO - --- Expansion 3/3 ---\n",
      "2024-12-23 21:04:53,714 - INFO - A combination of general searches and domain-specific searches would likely yield useful results. Start with broad terms and then narrow down the focus based on specific keywords from each document.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 21:04:53,724 - INFO - Expansion 3/3 - Generated 5 results\n",
      "2024-12-23 21:04:53,725 - INFO - Expansion 3 - Avg Score: -8.821\n",
      "2024-12-23 21:04:53,725 - INFO - Updating best terms and results (Expansion 3)...\n",
      "2024-12-23 21:04:53,725 - INFO - Total unique results so far: 13\n",
      "2024-12-23 21:04:53,725 - INFO - Final Score: -3.792\n"
     ]
    }
   ],
   "source": [
    "result = b(\"What are the consequences of being too fat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d19c266-160e-405f-9271-b1779489e729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    terms=['are', 'for', 'fat', 'imaging', 'social', 'obesity', 'exercise', 'abdominal', 'individuals', 'appliances', 'almanac', 'genetic', 'metrics', 'being', 'people', 'lifestyles', 'tissue', 'insulin', 'determinants', 'habits', 'usage', 'conservation', 'overweight', 'efficiency', 'dataset', 'balance', 'anthropometric', 'lifestyle', 'factors', 'the', 'home', 'and', 'health', 'weight', 'effects', 'modifications', 'non-intrusive', 'lipase', 'energy', 'indicators', 'body', 'aging', 'stigma', 'in', 'status', 'consequences', 'ageing', 'fat?', 'characteristics', 'long-term', 'eating', 'What', '(NILM)', 'sensitivity', 'lipoprotein', 'load', 'disaggregation', 'visceral', 'techniques', 'household', 'distribution', 'monitoring', 'healthy', 'of', 'mental', 'adipose', 'minutely', 'power', 'too', 'appetite', 'assessment', 'image', 'composition', 'consumption'],\n",
       "    results=['When prevention fails, medicinal treatment of obesity may become a necessity. Any strategic medicinal development must recognize that obesity is a chronic, stigmatized and costly disease that is increasing in prevalence. Because obesity can rarely be cured, treatment strategies are effective only as long as they are used, and combined therapy may be more effective than monotherapy. For a drug to have significant impact on body weight it must ultimately reduce energy intake, increase energy expenditure, or both. Currently approved drugs for long-term treatment of obesity include sibutramine, which inhibits food intake, and orlistat, which blocks fat digestion.', 'When prevention fails, medicinal treatment of obesity may become a necessity. Any strategic medicinal development must recognize that obesity is a chronic, stigmatized and costly disease that is increasing in prevalence. Because obesity can rarely be cured, treatment strategies are effective only as long as they are used, and combined therapy may be more effective than monotherapy. For a drug to have significant impact on body weight it must ultimately reduce energy intake, increase energy expenditure, or both. Currently approved drugs for long-term treatment of obesity include sibutramine, which inhibits food intake, and orlistat, which blocks fat digestion.', 'When prevention fails, medicinal treatment of obesity may become a necessity. Any strategic medicinal development must recognize that obesity is a chronic, stigmatized and costly disease that is increasing in prevalence. Because obesity can rarely be cured, treatment strategies are effective only as long as they are used, and combined therapy may be more effective than monotherapy. For a drug to have significant impact on body weight it must ultimately reduce energy intake, increase energy expenditure, or both. Currently approved drugs for long-term treatment of obesity include sibutramine, which inhibits food intake, and orlistat, which blocks fat digestion.', 'When prevention fails, medicinal treatment of obesity may become a necessity. Any strategic medicinal development must recognize that obesity is a chronic, stigmatized and costly disease that is increasing in prevalence. Because obesity can rarely be cured, treatment strategies are effective only as long as they are used, and combined therapy may be more effective than monotherapy. For a drug to have significant impact on body weight it must ultimately reduce energy intake, increase energy expenditure, or both. Currently approved drugs for long-term treatment of obesity include sibutramine, which inhibits food intake, and orlistat, which blocks fat digestion.', 'Excess intra-abdominal adipose tissue accumulation, often termed visceral obesity, is part of a phenotype including dysfunctional subcutaneous adipose tissue expansion and ectopic triglyceride storage closely related to clustering cardiometabolic risk factors. Hypertriglyceridemia; increased free fatty acid availability; adipose tissue release of proinflammatory cytokines; liver insulin resistance and inflammation; increased liver VLDL synthesis and secretion; reduced clearance of triglyceride-rich lipoproteins; presence of small, dense LDL particles; and reduced HDL cholesterol levels are among the many metabolic alterations closely related to this condition. Age, gender, genetics, and ethnicity are broad etiological factors contributing to variation in visceral adipose tissue accumulation. Specific mechanisms responsible for proportionally increased visceral fat storage when facing positive energy balance and weight gain may involve sex hormones, local cortisol production in abdominal adipose tissues, endocannabinoids, growth hormone, and dietary fructose. Physiological characteristics of abdominal adipose tissues such as adipocyte size and number, lipolytic responsiveness, lipid storage capacity, and inflammatory cytokine production are significant correlates and even possible determinants of the increased cardiometabolic risk associated with visceral obesity. Thiazolidinediones, estrogen replacement in postmenopausal women, and testosterone replacement in androgen-deficient men have been shown to favorably modulate body fat distribution and cardiometabolic risk to various degrees. However, some of these therapies must now be considered in the context of their serious side effects. Lifestyle interventions leading to weight loss generally induce preferential mobilization of visceral fat. In clinical practice, measuring waist circumference in addition to the body mass index could be helpful for the identification and management of a subgroup of overweight or obese patients at high cardiometabolic risk.'],\n",
       "    score=np.float32(-3.7919319),\n",
       "    summary=Prediction(\n",
       "    reasoning=\"The context provided details about obesity and its treatment.  It addresses the fact that obesity is a chronic, expensive, and difficult-to-cure condition. The question asks about the consequences of being too fat, which this context can help answer by discussing obesity's impacts on health and metabolic function.\",\n",
       "    answer='Being overweight or obese has numerous negative consequences for health, including increased risk of:\\n* Cardiovascular disease \\n* Type 2 diabetes\\n* Certain types of cancer\\n* Sleep apnea \\n* Joint problems\\n\\nThe effects of visceral fat (excess fat stored in the abdominal area) are particularly detrimental.  Excess intra-abdominal adipose tissue accumulation is linked to insulin resistance, elevated blood pressure, and high cholesterol levels. This can lead to complications like heart disease, stroke, and type 2 diabetes.'\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5483a-26ca-4edf-92ab-63984deb465d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
